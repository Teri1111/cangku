{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import httpx\n",
    "from parsel import Selector\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoteContent:\n",
    "    \"\"\"\n",
    "    帖子简介存储容器\n",
    "    \"\"\"\n",
    "    title: str = \"\"  # 帖子标题\n",
    "    author: str = \"\"  # 帖子作者\n",
    "    publish_date: str = \"\"  # 帖子发表日期\n",
    "    detail_link: str = \"\"  # 帖子详情\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"\"\"\n",
    "            Title: {self.title}\n",
    "            User: {self.author}\n",
    "            Publish Date: {self.publish_date}\n",
    "            Detail Link: {self.detail_link}        \n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "class NotePushComment:\n",
    "    \"\"\"\n",
    "    推文存储容器\n",
    "    \"\"\"\n",
    "    push_user_name: str = \"\"  # 推文人\n",
    "    push_cotent: str = \"\"  # 推文内容\n",
    "    push_time: str = \"\"  # 推文时间\n",
    "\n",
    "    def __repr__(self):\n",
    "        # 这里有用repr的原因是以为了NoteContentDetail的push_comment List结构方便打印\n",
    "        return f\"NotePushComment(push_user_name='{self.push_user_name}', push_cotent='{self.push_cotent}', push_time='{self.push_time}')\"\n",
    "\n",
    "\n",
    "class NoteContentDetail:\n",
    "    \"\"\"\n",
    "    帖子\n",
    "    \"\"\"\n",
    "    title: str = \"\"  # 帖子标题\n",
    "    author: str = \"\"  # 帖子作者\n",
    "    publish_datetime: str = \"\"  # 帖子发表日期\n",
    "    detail_link: str = \"\"  # 帖子详情链接\n",
    "    push_comment: List[NotePushComment] = []  # 帖子推文列表，相当于国内评论列表\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"\"\"\n",
    "Title: {self.title}\n",
    "User: {self.author}\n",
    "Publish Datetime: {self.publish_datetime}\n",
    "Detail Link: {self.detail_link}\n",
    "Push Comments: {self.push_comment}        \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = os.path.join('/Users/meinv/Desktop', '1.txt')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(file_path):\n",
    "    print(f'yes')\n",
    "else:\n",
    "    print('no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file_path, 'r') as file:\n",
    "    content = file.read()\n",
    "\n",
    "html_content = content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用 lxml 解析器\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    soup = BeautifulSoup(html_content, 'lxml')\n",
    "    print(\"使用 lxml 解析器\")\n",
    "except Exception as e:\n",
    "    print(f\"lxml 解析器失败: {e}\")\n",
    "    # 切换到内置的 html.parser 解析器\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    print(\"切换到 html.parser 解析器\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def parse_html_use_parse(html_content: str):\n",
    "    \"\"\"\n",
    "    使用parsel提取帖子标题、作者、发布日期，基于xpath选择器提取\n",
    "    :param html_content: html源代码内容\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # 初始化一个帖子保存容器\n",
    "    note_content = NoteContent()\n",
    "    # 使用parsel创建选择器对象\n",
    "    selector = Selector(text=html_content)\n",
    "    # 使用XPath提取标题并去除左右空格\n",
    "    note_content.title = selector.xpath(\"//div[@class='r-ent']/div[@class='title']/a/text()\").extract_first().strip()\n",
    "    # 使用XPath提取作者\n",
    "    note_content.author = selector.xpath(\"//div[@class='r-ent']/div[@class='meta']/div[@class='author']/text()\").extract_first().strip()\n",
    "    # 使用XPath提取发布日期\n",
    "    note_content.publish_date = selector.xpath(\"//div[@class='r-ent']/div[@class='meta']/div[@class='date']/text()\").extract_first().strip()\n",
    "    # 使用XPath提取帖子链接\n",
    "    note_content.detail_link = selector.xpath(\"//div[@class='r-ent']/div[@class='title']/a/@href\").extract_first()\n",
    "\n",
    "    print(\"parsel\" + \"*\" * 30)\n",
    "    print(note_content)\n",
    "    print(\"parsel\" + \"*\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parsel******************************\n",
      "\n",
      "Title: [問卦] 川普好猛 台積最低到980\n",
      "User: Skyblueway\n",
      "Publish Date: 7/19\n",
      "Detail Link: /bbs/Gossiping/M.1721356535.A.18B.html        \n",
      "\n",
      "parsel******************************\n"
     ]
    }
   ],
   "source": [
    "parse_html_use_parse(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
